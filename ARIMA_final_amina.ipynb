{
 "cells": [
  {
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "# ARIMA model\n",
    "\n",
    "We will fit ARIMA model using water_level in Dusseldorf, sequence by sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading and visualising the data\n",
    "The station in Dusseldorf is #6335050"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "river_df = pd.read_csv('./stations/station_6335050_river_data.csv')\n",
    "river_df.date = pd.to_datetime(river_df.date, format='%Y-%m-%d')\n",
    "river_df = river_df.set_index('date')"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-559596dc475e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mriver_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../stations/station_6335050_river_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mriver_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mriver_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mriver_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mriver_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../stations/station_6335050_river_data.csv' does not exist: b'../stations/station_6335050_river_data.csv'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../stations/station_6335050_river_data.csv' does not exist: b'../stations/station_6335050_river_data.csv'",
     "output_type": "error"
    }
   ]
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "river_df.delta1.plot()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Function for fitting one sequence of water_level\n",
    "\n",
    "Our data is clearly non-stationary (see river_data_exploration_final_amina.ipynb)  \n",
    "so we will use Box-Cox transform to ensure stationarity.  \n",
    "\n",
    "Only then we can try to fit ARIMA.  \n",
    "\n",
    "At the end we will apply reverse Box-Cox transformation to get the output data in initial form.  \n",
    "\n",
    "The parameters are:\n",
    "df - the pandas dataframe with water_level column from river_data.csv;  \n",
    "the gaps (dates without any data) should be filled by NaNs\n",
    "pred_start - the first day after the sequence, it signifies the first day of the gap, the first day we should predict\n",
    "pred_end - the last day, that we should fill with our predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "MAX_PARAM_COUNT = 8\n",
    "\n",
    "def fit_and_predict(df, pred_start, pred_end):\n",
    "    head_df = df[df.index < pred_start]\n",
    "    train, val = train_test_split(head_df.water_level.values, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    norm, lambd = boxcox(train)\n",
    "    train = (train**lambd - 1)/lambd\n",
    "    \n",
    "    p = q = range(0, min(MAX_PARAM_COUNT, int(np.sqrt(train.shape[0]))))\n",
    "    d = range(1, 2)\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "    best_r2 = -np.inf\n",
    "    best_params = pdq[0]\n",
    "    best_arima = None\n",
    "    \n",
    "    for (p, d, q) in pdq:\n",
    "        if p == 0 and d == 0 and q == 0: continue\n",
    "        \n",
    "        arima = ARIMA(train, (p, d, q))\n",
    "        try:\n",
    "            arima_fit = arima.fit()\n",
    "        except LinAlgError:\n",
    "            continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "            \n",
    "        if d == 1:\n",
    "            pred = arima_fit.forecast(len(val))[0]\n",
    "        else:\n",
    "            pred = arima_fit.forecast(len(val))[0]\n",
    "\n",
    "        try:\n",
    "            r2 = r2_score(val, pred)\n",
    "        except ValueError:\n",
    "            print(f'Flawed prediction for {p}, {d}, {q}')\n",
    "            continue\n",
    "            \n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_params = (p, d, q)\n",
    "            best_arima = arima_fit\n",
    "        \n",
    "    print('Best r2:', best_r2)\n",
    "    print('Best params:', best_params)\n",
    "    norm, lambd = boxcox(head_df.water_level.values)\n",
    "    print(f'Best params: {best_params}')\n",
    "    \n",
    "    arima = ARIMA(norm, best_params).fit()\n",
    "\n",
    "    if best_params[1] == 1:\n",
    "        pred_fin = arima.forecast(17)[0]\n",
    "    else:\n",
    "        pred_fin = best_arima.forecast(17)[0]\n",
    "    \n",
    "    pred_dates = pd.date_range(pred_start, pred_end).to_series().reset_index(drop=True)\n",
    "        \n",
    "    def invboxcox(y):\n",
    "          return ((y*lambd)+1)**(1/lambd)\n",
    "    \n",
    "    df.loc[pred_dates, 'water_level'] = invboxcox(pred_fin)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    },
    "trusted": true
   },
   "cell_type": "markdown",
   "source": [
    "## Setting up our dataset and feeding it to ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_range = pd.date_range(river_df.index.min(), river_df.index.max()+pd.Timedelta(days=1))\n",
    "river_df = river_df.reindex(full_range, fill_value=np.NaN)\n",
    "\n",
    "next_gap = river_df.water_level.isnull().idxmax()\n",
    "tail_gap = next_gap + pd.Timedelta(days=16)\n",
    "\n",
    "while next_gap < pd.to_datetime('2013-01-01'):\n",
    "    print(f'Working with gap {next_gap} - {tail_gap}.')\n",
    "    fit_and_predict(river_df, next_gap, tail_gap)\n",
    "    river_df[river_df.index <= tail_gap].water_level.plot()\n",
    "    \n",
    "    next_gap = river_df.water_level.isnull().idxmax()\n",
    "    tail_gap = next_gap + pd.Timedelta(days=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    },
    "trusted": false
   },
   "cell_type": "markdown",
   "source": [
    "## Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "river_df[['water_level']].to_csv('station6335050_water_level.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking the results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "river_df[100:110]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "river_df.water_level.plot()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}