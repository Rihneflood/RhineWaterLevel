{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "rd = pd.read_csv(\"river_data.csv\")\n",
    "rs = pd.read_csv(\"river_stations.csv\")\n",
    "wd = pd.read_csv(\"weather_data.csv\")\n",
    "ws = pd.read_csv(\"weather_stations.csv\")\n",
    "station_no_river_dusseldorf = \"6335050\"\n",
    "station_no_river_cologne = \"6335060\"\n",
    "station_no_river_andernach = \"6335070\"\n",
    "station_no_river_friedrich = \"6335076\"\n",
    "station_no_river_menden = \"6335045\"\n",
    "station_no_river_eitorf = \"6335046\"\n",
    "station_no_weather_sollingen = \"4741\"\n",
    "station_no_weather_cologne = \"2968\"\n",
    "\n",
    "#saving the data size\n",
    "rd_m, rd_n = rd.shape\n",
    "rs_m, rs_n = rs.shape\n",
    "wd_m, wd_n = wd.shape\n",
    "ws_m, ws_n = ws.shape\n",
    "\n",
    "#2\n",
    "rd_c = pd.read_csv('stations/station_' + station_no_river_cologne + '_river_data.csv')\n",
    "rd_c.date = pd.to_datetime(rd_c.date, format='%Y-%m-%d')\n",
    "rd_c = rd_c.set_index('date')\n",
    "columns = ['station_no','year', 'month']\n",
    "rd_c.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "rd_d = pd.read_csv('stations/station_' + station_no_river_dusseldorf + '_river_data.csv')\n",
    "rd_d.date = pd.to_datetime(rd_d.date, format='%Y-%m-%d')\n",
    "rd_d = rd_d.set_index('date')\n",
    "columns = ['station_no','year', 'month']\n",
    "rd_d.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "rd_a = pd.read_csv('stations/station_' + station_no_river_andernach + '_river_data.csv')\n",
    "rd_a.date = pd.to_datetime(rd_a.date, format='%Y-%m-%d')\n",
    "rd_a = rd_a.set_index('date')\n",
    "columns = ['station_no','year', 'month','delta1', 'delta2', 'delta3', 'water_level' ]\n",
    "rd_a.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "rd_f = pd.read_csv('stations/station_' + station_no_river_friedrich + '_river_data.csv')\n",
    "rd_f.date = pd.to_datetime(rd_f.date, format='%Y-%m-%d')\n",
    "rd_f = rd_f.set_index('date')\n",
    "columns = ['station_no','year', 'month','delta1', 'delta2', 'delta3', 'water_level' ]\n",
    "rd_f.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "rd_m = pd.read_csv('stations/station_' + station_no_river_menden + '_river_data.csv')\n",
    "rd_m.date = pd.to_datetime(rd_m.date, format='%Y-%m-%d')\n",
    "rd_m = rd_m.set_index('date')\n",
    "columns = ['station_no','year', 'month','delta1', 'delta2', 'delta3', 'water_level' ]\n",
    "#columns = ['station_no','year', 'month' ]\n",
    "rd_m.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "rd_e = pd.read_csv('stations/station_' + station_no_river_menden + '_river_data.csv')\n",
    "rd_e.date = pd.to_datetime(rd_e.date, format='%Y-%m-%d')\n",
    "rd_e = rd_e.set_index('date')\n",
    "columns = ['station_no','year', 'month','delta1', 'delta2', 'delta3', 'water_level' ]\n",
    "#columns = ['station_no','year', 'month' ]\n",
    "rd_e.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "#rd_d.delta1.plot()\n",
    "\n",
    "\n",
    "#3\n",
    "combine_df_c = pd.merge(rd_c, rd_a, how='left', on=['date'])\n",
    "#combine_df_c = pd.merge(combine_df_c, rd_f, how='left', on=['date'])\n",
    "\n",
    "columns = ['delta1', 'delta2', 'delta3']\n",
    "rd_c.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "combine_df_d = pd.merge(rd_d, rd_c, how='left', on=['date'])\n",
    "\n",
    "#4\n",
    "combine_df_d = pd.merge(combine_df_d, rd_a, how='left', on=['date'])\n",
    "combine_df_d = pd.merge(combine_df_d, rd_f, how='left', on=['date'])\n",
    "combine_df_d = pd.merge(combine_df_d, rd_m, how='left', on=['date'])\n",
    "combine_df_d = pd.merge(combine_df_d, rd_e, how='left', on=['date'])\n",
    "combine_df_d.rename(columns={'water_level_x': 'water_level'}, inplace=True)\n",
    "\n",
    "#5\n",
    "def define_X_y(df, pred_start, prev_X, prev_y):\n",
    "    head_df = df[df.index < pred_start]\n",
    "    #head_df.drop(['station_no', 'STATIONS_ID', 'year_x', 'month_x','RSF', 'SH_TAG', 'NSH_TAG'], axis=1, inplace=True)\n",
    "    #head_df['RS_y'] = head_df.RS.shift(1)\n",
    "    #head_df['RS_t'] = head_df.RS.shift(-1)\n",
    "    #print(head_df)\n",
    "    \n",
    "    y_last = head_df['water_level'][-1]\n",
    "    X = head_df\n",
    "    y1 = head_df.water_level.shift(-1)\n",
    "    y2 = head_df.water_level.shift(-2)\n",
    "    y3 = head_df.water_level.shift(-3)\n",
    "    X = np.nan_to_num(X, nan=0)\n",
    "    #scaler = MinMaxScaler()\n",
    "    X_normalized = X#scaler.fit_transform(X)\n",
    "    #X_normalized = preprocessing.normalize(X, norm='l2')#X\n",
    "    x_last = X_normalized[-1,:]\n",
    "    x_last = x_last.reshape((1, np.shape(x_last)[0]))\n",
    "    X_normalized = X_normalized[3:-3]\n",
    "    y1 = y1[3:-3]\n",
    "    y2 = y2[3:-3]\n",
    "    y3 = y3[3:-3]\n",
    "    if prev_X.shape[0] > 3:\n",
    "        X_normalized = np.concatenate((prev_X, X_normalized))\n",
    "        y1 = np.concatenate((prev_y[:,0], y1))\n",
    "        y2 = np.concatenate((prev_y[:,1], y2))\n",
    "        y3 = np.concatenate((prev_y[:,2], y3))\n",
    "    return X_normalized, x_last, y_last, y1, y2, y3\n",
    "\n",
    "#6\n",
    "\n",
    "def train_the_model(X, x_last, y_last, y1, y2, y3):\n",
    "    X_train, X_test, y_train1, y_test1 = train_test_split(X, y1, test_size=0.05, random_state=0)\n",
    "    regressor1 = LinearRegression()  \n",
    "    regressor1.fit(X_train, y_train1) #training the algorithm\n",
    "  \n",
    "    clf1 = SVR(kernel='poly', C=100, epsilon=0.01,tol = 0.0001, max_iter = 200)\n",
    "    clf1.fit(X_train, y_train1)\n",
    "    y_real_svm1 = clf1.predict(x_last)\n",
    "    y_real_svm1 = y_real_svm1 - y_last   \n",
    "\n",
    "    y_pred1 = regressor1.predict(X_test)\n",
    "    y_pred1 = np.diff(y_pred1)\n",
    "    y_test1 = np.diff(y_test1)\n",
    "    y_real1 = regressor1.predict(x_last)\n",
    "    y_real1 = y_real1 - y_last\n",
    "    \n",
    "    X_train, X_test, y_train2, y_test2 = train_test_split(X, y2, test_size=0.05, random_state=5)\n",
    "    regressor2 = LinearRegression()  \n",
    "    regressor2.fit(X_train, y_train2) #training the algorithm\n",
    "\n",
    "    clf2 = SVR(kernel='poly', C=100, epsilon=0.01,tol = 0.0001, max_iter = 200)\n",
    "    clf2.fit(X_train, y_train2)\n",
    "    y_real_svm2 = clf2.predict(x_last)\n",
    "    y_real_svm2 = y_real_svm2 - y_last  \n",
    "    \n",
    "    y_pred2 = regressor2.predict(X_test)\n",
    "    y_pred2 = np.diff(y_pred2)\n",
    "    y_test2 = np.diff(y_test2)\n",
    "    y_real2 = regressor2.predict(x_last)\n",
    "    y_real2 = y_real2 - y_last\n",
    "\n",
    "    X_train, X_test, y_train3, y_test3 = train_test_split(X, y3, test_size=0.05, random_state=2)\n",
    "    regressor3 = LinearRegression()  \n",
    "    regressor3.fit(X_train, y_train3) #training the algorithm\n",
    "    \n",
    "    clf3 = SVR(kernel='poly', C=100, epsilon=0.01,tol = 0.0001, max_iter = 200)\n",
    "    clf3.fit(X_train, y_train3)\n",
    "    y_real_svm3 = clf3.predict(x_last)\n",
    "    y_real_svm3 = y_real_svm3 - y_last \n",
    "    \n",
    "    y_pred3 = regressor3.predict(X_test)\n",
    "    y_pred3 = np.diff(y_pred3)\n",
    "    y_test3 = np.diff(y_test3)\n",
    "    y_real3 = regressor3.predict(x_last)\n",
    "    y_real3 = y_real3 - y_last\n",
    "    \n",
    "    y_true = np.concatenate((y_test1, y_test2, y_test3), axis=None)\n",
    "    y_pred = np.concatenate((y_pred1, y_pred2, y_pred3), axis=None)\n",
    "    y_real = np.concatenate((y_real1, y_real2, y_real3), axis=None)\n",
    "    y_real = y_real.reshape((np.shape(y_real)[0],1))\n",
    "    y_real_svm = np.concatenate((y_real_svm1, y_real_svm2, y_real_svm3), axis=None)\n",
    "    y_real_svm = y_real_svm.reshape((np.shape(y_real_svm)[0],1))\n",
    "    return y_true, y_pred, y_real, y_real_svm\n",
    "\n",
    "skip_missing_days = 16\n",
    "full_range = pd.date_range(combine_df_c.index.min(), combine_df_c.index.max()+pd.Timedelta(days=1)) #TODO add last day!\n",
    "combine_df_c = combine_df_c.reindex(full_range, fill_value=np.NaN)\n",
    "\n",
    "next_gap = pd.to_datetime(combine_df_c.water_level.isnull().idxmax())\n",
    "tail_gap = next_gap + pd.Timedelta(days=skip_missing_days)\n",
    "prev_X = pd.DataFrame(np.zeros([1, 9])*0)\n",
    "prev_y = pd.DataFrame(np.zeros([1, 3])*0)\n",
    "r2_results = np.zeros(1)\n",
    "X_real_test_c = np.zeros([1,np.shape(combine_df_c)[1]])\n",
    "i=0\n",
    "y_real_test_c = np.zeros([1,1])\n",
    "y_real_test_svm_c = np.zeros([1,1])\n",
    "\n",
    "while next_gap:\n",
    "    X, x_last, y_last, y1, y2, y3 = define_X_y(combine_df_c, next_gap, prev_X, prev_y)\n",
    "    X_real_test_c = np.vstack((X_real_test_c, x_last))\n",
    "    X = np.nan_to_num(X, nan=0)\n",
    "    indexNames = combine_df_c[ combine_df_c.index < tail_gap ].index\n",
    "    combine_df_c.drop(indexNames , inplace=True)\n",
    "    y1 = np.nan_to_num(y1, nan=0)\n",
    "    y2 = np.nan_to_num(y2, nan=0)\n",
    "    y3 = np.nan_to_num(y3, nan=0)\n",
    "    y_true, y_pred, y_real, y_real_svm = train_the_model(X, x_last, y_last, y1,y2,y3)\n",
    "    y_real_test_c = np.vstack((y_real_test_c, y_real))\n",
    "    y_real_test_svm_c = np.vstack((y_real_test_svm_c, y_real_svm))\n",
    "    if np.shape(combine_df_c)[0] < 2:\n",
    "        break\n",
    "    next_gap = pd.to_datetime(combine_df_c.water_level.isnull().idxmax())\n",
    "    tail_gap = next_gap + pd.Timedelta(days=skip_missing_days)\n",
    "    prev_X = X\n",
    "    prev_y = [y1, y2, y3]\n",
    "    prev_y = np.transpose(prev_y)\n",
    "    i += 1\n",
    "    print(i)\n",
    "        #combine_df_c[next_gap < combine_df_c.index & tail_gap > combine_df_c.index]\n",
    "        \n",
    "\n",
    "X_real_test_c = X_real_test_c[1:-1,:]\n",
    "y_real_test_c = y_real_test_c[1:-3,:]\n",
    "y_real_test_svm_c = y_real_test_svm_c[1:-3,:]\n",
    "r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "skip_missing_days = 16\n",
    "full_range = pd.date_range(combine_df_d.index.min(), combine_df_d.index.max()+pd.Timedelta(days=1)) #TODO add last day!\n",
    "combine_df_d = combine_df_d.reindex(full_range, fill_value=np.NaN)\n",
    "\n",
    "next_gap = pd.to_datetime(combine_df_d.water_level.isnull().idxmax())\n",
    "tail_gap = next_gap + pd.Timedelta(days=skip_missing_days)\n",
    "prev_X = pd.DataFrame(np.zeros([1, 9])*0)\n",
    "prev_y = pd.DataFrame(np.zeros([1, 3])*0)\n",
    "r2_results = np.zeros(1)\n",
    "X_real_test_d = np.zeros([1,np.shape(combine_df_d)[1]])\n",
    "i=0\n",
    "y_real_test_d = np.zeros([1,1])\n",
    "y_real_test_svm_d = np.zeros([1,1])\n",
    "\n",
    "\n",
    "while next_gap:\n",
    "    X, x_last, y_last, y1, y2, y3 = define_X_y(combine_df_d, next_gap, prev_X, prev_y)\n",
    "    X_real_test_d = np.vstack((X_real_test_d, x_last))\n",
    "    X = np.nan_to_num(X, nan=0)\n",
    "    indexNames = combine_df_d[ combine_df_d.index < tail_gap ].index\n",
    "    combine_df_d.drop(indexNames , inplace=True)\n",
    "    y1 = np.nan_to_num(y1, nan=0)\n",
    "    y2 = np.nan_to_num(y2, nan=0)\n",
    "    y3 = np.nan_to_num(y3, nan=0)\n",
    "    y_true, y_pred, y_real, y_real_svm = train_the_model(X,x_last, y_last, y1,y2,y3)\n",
    "    y_real_test_d = np.vstack((y_real_test_d, y_real))\n",
    "    y_real_test_svm_d = np.vstack((y_real_test_svm_d, y_real_svm))\n",
    "    if np.shape(combine_df_d)[0] < 2:\n",
    "        break\n",
    "    next_gap = pd.to_datetime(combine_df_d.water_level.isnull().idxmax())\n",
    "    tail_gap = next_gap + pd.Timedelta(days=skip_missing_days)\n",
    "    prev_X = X\n",
    "    prev_y = [y1, y2, y3]\n",
    "    prev_y = np.transpose(prev_y)\n",
    "    i += 1\n",
    "    print(i)\n",
    "        #combine_df_c[next_gap < combine_df_c.index & tail_gap > combine_df_c.index]\n",
    "        \n",
    "X_real_test_d = X_real_test_d[1:-1,:]\n",
    "y_real_test_d = y_real_test_d[1:-3,:]\n",
    "y_real_test_svm_d = y_real_test_svm_d[1:-3,:]\n",
    "r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "y_real_test = np.vstack((y_real_test_d, y_real_test_c))\n",
    "predict_df = pd.read_csv('./to_predict.csv', index_col=False)\n",
    "\n",
    "\n",
    "predict_df['delta'] = y_real_test\n",
    "\n",
    "\n",
    "predict_df.to_csv('./team9submission.csv', index=False)\n",
    "\n",
    "\n",
    "y_real_test_svm = np.vstack((y_real_test_svm_d, y_real_test_svm_c))\n",
    "predict_df = pd.read_csv('./to_predict.csv', index_col=False)\n",
    "\n",
    "\n",
    "predict_df['delta'] = y_real_test_svm\n",
    "\n",
    "\n",
    "np.mean(y_real_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
